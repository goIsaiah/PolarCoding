{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b9b47760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === Patched Polar testbench (drop-in cell) ===\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "# ----------------------------\n",
    "# Utilities\n",
    "# ----------------------------\n",
    "def is_power_of_two(n):\n",
    "    return (n & (n-1)) == 0 and n > 0\n",
    "\n",
    "def bitrev_premutation(N):\n",
    "    \"\"\"Bit-reversal permutation (kept for reference; NOT used by canonical SC).\"\"\"\n",
    "    if N == 1:\n",
    "        return np.array([0], dtype=int)\n",
    "    n = int(np.log2(N))\n",
    "    br = np.empty(N, dtype=int)\n",
    "    for i in range(N):\n",
    "        b = format(i, '0{}b'.format(n))[::-1]\n",
    "        br[i] = int(b, 2)\n",
    "    return br\n",
    "\n",
    "# ----------------------------\n",
    "# Recursive polar transform (canonical natural-order)\n",
    "# ----------------------------\n",
    "def polar_transform(u):\n",
    "    \"\"\"Canonical recursive natural-order polar transform: x = F^{âŠ—n} * u (recursive).\n",
    "    This is the same transform your current code uses (even/odd recursion).\"\"\"\n",
    "    u = np.asarray(u, dtype=int)\n",
    "    N = len(u)\n",
    "    if N == 1:\n",
    "        return u.copy().astype(np.int8)\n",
    "    u_even = u[0:N:2]\n",
    "    u_odd = u[1:N:2]\n",
    "    upper = polar_transform((u_even ^ u_odd) % 2)\n",
    "    lower = polar_transform(u_odd)\n",
    "    return np.concatenate([upper, lower]).astype(np.int8)\n",
    "\n",
    "# ----------------------------\n",
    "# Bhattacharyya Z and frozen selection (direct canonical mapping)\n",
    "# ----------------------------\n",
    "def bhattacharyya_parameter(p, N):\n",
    "    \"\"\"Recursive Bhattacharyya parameters Z for BSC (length N).\"\"\"\n",
    "    Z = np.array([2.0 * np.sqrt(p * (1.0 - p))])\n",
    "    while len(Z) < N:\n",
    "        Z_next = []\n",
    "        for z in Z:\n",
    "            Z_next.append(2*z - z*z)  # 'upper' channel Bhattacharyya\n",
    "            Z_next.append(z*z)        # 'lower' channel Bhattacharyya\n",
    "        Z = np.array(Z_next)\n",
    "    return Z\n",
    "\n",
    "def select_frozen_direct(N, K, p_design):\n",
    "    \"\"\"\n",
    "    Select K best channels and create correct masks\n",
    "    for BOTH canonical (decoder) and natural (encoder).\n",
    "    \"\"\"\n",
    "    # logical Bhattacharyya values\n",
    "    Z = bhattacharyya_parameter(p_design, N)\n",
    "    logical_best = np.argsort(Z)[:K]     # logical indices 0..N-1\n",
    "\n",
    "    # === MAP logical -> canonical order ===\n",
    "    # canonical = bit-reversed ordering of logical indices\n",
    "    br = bitrev_premutation(N)           # br[natural] = logical\n",
    "    inv_br = np.argsort(br)              # inv_br[logical] = natural\n",
    "\n",
    "    # canonical ordering is just logical ordering\n",
    "    # SC decoder expects canonical positions\n",
    "    info_positions_canonical = np.sort(logical_best)\n",
    "\n",
    "    # === MAP canonical -> natural (for encoder & final extraction) ===\n",
    "    info_positions_natural = np.sort(inv_br[info_positions_canonical])\n",
    "\n",
    "    # build natural frozen mask (for encoder)\n",
    "    frozen_mask_natural = np.ones(N, dtype=bool)\n",
    "    frozen_mask_natural[info_positions_natural] = False\n",
    "\n",
    "    # build canonical frozen mask (for decoder)\n",
    "    frozen_mask_canonical = np.ones(N, dtype=bool)\n",
    "    frozen_mask_canonical[info_positions_canonical] = False\n",
    "\n",
    "    return (frozen_mask_natural, info_positions_natural,\n",
    "            frozen_mask_canonical, info_positions_canonical)\n",
    "\n",
    "# ----------------------------\n",
    "# Channel, LLR helpers\n",
    "# ----------------------------\n",
    "def bsc(x, p):\n",
    "    flips = (np.random.rand(len(x)) < p).astype(np.int8)\n",
    "    return (x ^ flips).astype(np.int8)\n",
    "\n",
    "def bsc_llr(y, p, eps=1e-12):\n",
    "    # LLR for BSC (channel p). For BSC output y in {0,1}, LLR = log( P(y|0) / P(y|1) )\n",
    "    p_safe = min(max(float(p), eps), 1.0 - eps)\n",
    "    alpha = np.log((1.0 - p_safe) / p_safe)\n",
    "    return (1 - 2*y) * alpha\n",
    "\n",
    "# ----------------------------\n",
    "# LLR combining (f,g) helpers\n",
    "# ----------------------------\n",
    "def f_min_sum(a, b):\n",
    "    a = np.array(a, dtype=float); b = np.array(b, dtype=float)\n",
    "    return np.sign(a * b) * np.minimum(np.abs(a), np.abs(b))\n",
    "\n",
    "def f_exact(a, b, eps=1e-12):\n",
    "    A = np.array(a, dtype=float)\n",
    "    B = np.array(b, dtype=float)\n",
    "    ta = np.tanh(A / 2.0)\n",
    "    tb = np.tanh(B / 2.0)\n",
    "    t = ta * tb\n",
    "    t = np.clip(t, -1.0 + eps, 1.0 - eps)\n",
    "    # 2*atanh(t) = log((1+t)/(1-t)) -> numerically via log1p\n",
    "    return np.log1p(t) - np.log1p(-t)\n",
    "\n",
    "# ----------------------------\n",
    "# Canonical recursive SC decoder (returns uhat in canonical order)\n",
    "# ----------------------------\n",
    "def sc_decode(llr, frozen_mask, u_frozen=None, use_exact_f=False):\n",
    "    \"\"\"Successive Cancellation recursive decoder.\n",
    "       - llr: length N (canonical order leaves)\n",
    "       - frozen_mask: boolean mask in canonical order (same order as llr)\n",
    "       - returns: uhat in canonical order\n",
    "    \"\"\"\n",
    "    if u_frozen is None:\n",
    "        u_frozen = np.zeros(len(frozen_mask), dtype=np.int8)\n",
    "    llr = np.array(llr, dtype=float)\n",
    "    frozen_mask = np.array(frozen_mask, dtype=bool)\n",
    "    u_frozen = np.array(u_frozen, dtype=np.int8)\n",
    "\n",
    "    def rec(llr_sub, frozen_sub, u_frozen_sub):\n",
    "        n = len(llr_sub)\n",
    "        if n == 1:\n",
    "            if frozen_sub[0]:\n",
    "                return np.array([u_frozen_sub[0]], dtype=np.int8)\n",
    "            else:\n",
    "                return np.array([0 if llr_sub[0] >= 0 else 1], dtype=np.int8)\n",
    "        n2 = n // 2\n",
    "        a = llr_sub[:n2]; b = llr_sub[n2:]\n",
    "        f_llr = f_exact(a, b) if use_exact_f else f_min_sum(a, b)\n",
    "        uhat_up = rec(f_llr, frozen_sub[:n2], u_frozen_sub[:n2])\n",
    "        # stable g\n",
    "        g_llr = b + ((-1) ** uhat_up) * a\n",
    "        uhat_low = rec(g_llr, frozen_sub[n2:], u_frozen_sub[n2:])\n",
    "        u_upper = (uhat_up ^ uhat_low).astype(np.int8)\n",
    "        u_lower = uhat_low.astype(np.int8)\n",
    "        return np.concatenate([u_upper, u_lower]).astype(np.int8)\n",
    "\n",
    "    return rec(llr, frozen_mask, u_frozen)\n",
    "\n",
    "# ----------------------------\n",
    "# (Optional) reordering wrapper -- kept for reference but NOT used\n",
    "# ----------------------------\n",
    "def sc_decode_with_reordering(llr, frozen_mask_nat, u_frozen_nat=None, use_exact_f=False):\n",
    "    \"\"\"Wrapper that converts NATURAL-order inputs into tree order, calls sc_decode,\n",
    "       then maps result back to NATURAL order. Kept for reference (not used).\"\"\"\n",
    "    N = len(frozen_mask_nat)\n",
    "    br = bitrev_premutation(N)        # natural -> bit-reversed mapping (index array)\n",
    "    inv_br = np.argsort(br)           # bit-reversed -> natural\n",
    "    frozen_mask_br = np.array(frozen_mask_nat, dtype=bool)[inv_br]\n",
    "    if u_frozen_nat is None:\n",
    "        u_frozen_nat = np.zeros(N, dtype=np.int8)\n",
    "    u_frozen_br = np.array(u_frozen_nat, dtype=np.int8)[inv_br]\n",
    "    uhat_br = sc_decode(llr, frozen_mask_br, u_frozen=u_frozen_br, use_exact_f=use_exact_f)\n",
    "    uhat_nat = np.zeros_like(uhat_br)\n",
    "    uhat_nat[br] = uhat_br\n",
    "    return uhat_nat\n",
    "\n",
    "def sc_natural_to_canonical(u_hat):\n",
    "    N = len(u_hat)\n",
    "    if N == 1:\n",
    "        return u_hat.copy()\n",
    "    \n",
    "    n_half = N // 2\n",
    "    up = sc_natural_to_canonical(u_hat[:n_half])\n",
    "    low = sc_natural_to_canonical(u_hat[n_half:])\n",
    "\n",
    "    out = np.empty(N, dtype=np.int8)\n",
    "    out[0::2] = (up ^ low) & 1\n",
    "    out[1::2] = low\n",
    "    return out\n",
    "\n",
    "# ----------------------------\n",
    "# Deterministic self-check (canonical ordering)\n",
    "# ----------------------------\n",
    "def deterministic_debug_once(N=8, K=4, p_design=0.05, use_exact_f=True, verbose=True):\n",
    "    \"\"\"Deterministic no-noise check using the new select_frozen_direct that\n",
    "    returns both natural & canonical masks/positions.\n",
    "    Encoder uses NATURAL info positions.\n",
    "    Decoder uses CANONICAL frozen mask.\n",
    "    After SC decode (canonical), map decoded bits to natural for final extraction.\n",
    "    \"\"\"\n",
    "    if not is_power_of_two(N):\n",
    "        raise ValueError(\"N must be a power of two\")\n",
    "\n",
    "    # select_frozen_direct now returns four items:\n",
    "    (frozen_mask_natural, info_positions_natural,\n",
    "     frozen_mask_canonical, info_positions_canonical) = select_frozen_direct(N, K, p_design)\n",
    "\n",
    "    u_frozen = np.zeros(N, dtype=np.int8)\n",
    "    msg = np.random.randint(0,2,size=len(info_positions_natural)).astype(np.int8)\n",
    "\n",
    "    # encoder (place message into NATURAL positions)\n",
    "    u = np.zeros(N, dtype=np.int8)\n",
    "    u[info_positions_natural] = msg\n",
    "    x = polar_transform(u)\n",
    "\n",
    "    # noiseless LLRs (very confident)\n",
    "    llr = bsc_llr(x, p=1e-9)\n",
    "\n",
    "    # SC decode: pass CANONICAL frozen mask (sc_decode returns canonical-order bits)\n",
    "    u_hat_canonical = sc_decode(llr, frozen_mask_canonical, u_frozen=u_frozen, use_exact_f=use_exact_f)\n",
    "\n",
    "    # Map decoded bits back to NATURAL order\n",
    "    # (your helper sc_natural_to_canonical is used as the inverse mapping here;\n",
    "    #  name is historically confusing but it performs canonical->natural mapping in your code)\n",
    "    u_hat = sc_natural_to_canonical(u_hat_canonical)\n",
    "\n",
    "    # final extraction uses NATURAL info positions\n",
    "    msg_hat = u_hat[info_positions_natural]\n",
    "    ok = np.array_equal(msg_hat, msg)\n",
    "\n",
    "    if verbose:\n",
    "        print(\"=== Deterministic Debug ===\")\n",
    "        print(\"N, K:\", N, K)\n",
    "        print(\"info_positions (natural):\", info_positions_natural)\n",
    "        print(\"info_positions (canonical):\", info_positions_canonical)\n",
    "        print(\"frozen_mask (natural):\", frozen_mask_natural.astype(int))\n",
    "        print(\"frozen_mask (canonical):\", frozen_mask_canonical.astype(int))\n",
    "        print(\"msg:\", msg.tolist())\n",
    "        print(\"u (full, natural):\", u.tolist())\n",
    "        print(\"x:\", x.tolist())\n",
    "        print(\"llr (sample 16):\", llr[:16].tolist())\n",
    "        print(\"u_hat (canonical):\", u_hat_canonical.tolist())\n",
    "        print(\"u_hat (natural):\", u_hat.tolist())\n",
    "        print(\"expected info (natural):\", msg.tolist())\n",
    "        print(\"decoded info (natural):\", msg_hat.tolist())\n",
    "        print(\"match?\", ok)\n",
    "\n",
    "    return ok\n",
    "\n",
    "# ----------------------------\n",
    "# Monte-Carlo (single N) - canonical ordering\n",
    "# ----------------------------\n",
    "def monte_carlo_polar_matrix(N=128, K=None, p_design=0.05, p_channel=None,\n",
    "                             trials=200, use_exact_f=True, verbose=True):\n",
    "    \"\"\"\n",
    "    Monte Carlo for a single N that uses the canonical frozen mask for decoding\n",
    "    and the natural info positions for encoding / final extraction.\n",
    "    \"\"\"\n",
    "    if not is_power_of_two(N):\n",
    "        raise ValueError(\"N must be power of two\")\n",
    "    if K is None:\n",
    "        K = N // 2\n",
    "    if p_channel is None:\n",
    "        p_channel = p_design\n",
    "\n",
    "    (frozen_mask_natural, info_positions_natural,\n",
    "     frozen_mask_canonical, info_positions_canonical) = select_frozen_direct(N, K, p_design)\n",
    "\n",
    "    u_frozen = np.zeros(N, dtype=np.int8)\n",
    "    K_actual = len(info_positions_natural)\n",
    "\n",
    "    bit_err = 0\n",
    "    block_err = 0\n",
    "    for t in range(trials):\n",
    "        msg = np.random.randint(0,2,size=K_actual).astype(np.int8)\n",
    "\n",
    "        # encoder (natural positions)\n",
    "        u = np.zeros(N, dtype=np.int8)\n",
    "        u[info_positions_natural] = msg\n",
    "        x = polar_transform(u)\n",
    "\n",
    "        # channel + LLR (LLRs are naturally aligned with leaves)\n",
    "        y = bsc(x, p_channel)\n",
    "        llr = bsc_llr(y, p_channel)\n",
    "\n",
    "        # DECODE: use canonical frozen mask (sc_decode returns canonical-order uhat)\n",
    "        u_hat_canonical = sc_decode(llr, frozen_mask_canonical, u_frozen=u_frozen, use_exact_f=use_exact_f)\n",
    "\n",
    "        # Map to natural ordering\n",
    "        u_hat = sc_natural_to_canonical(u_hat_canonical)\n",
    "\n",
    "        # Extract decoded message using NATURAL info positions\n",
    "        msg_hat = u_hat[info_positions_natural]\n",
    "\n",
    "        e = int(np.sum(msg_hat != msg))\n",
    "        bit_err += e\n",
    "        block_err += int(e > 0)\n",
    "\n",
    "        if verbose and (t % max(1, trials//10) == 0):\n",
    "            print(f\"Trial {t}/{trials}: bit_err={bit_err}, block_err={block_err}\")\n",
    "\n",
    "    ber = bit_err / (trials * K_actual)\n",
    "    bler = block_err / trials\n",
    "    return ber, bler\n",
    "\n",
    "# ----------------------------\n",
    "# Monte-Carlo sweep and plotting helper\n",
    "# ----------------------------\n",
    "def monte_carlo_sweep_and_plot(N_list, K_ratio=0.5, p_design=0.05, p_channel=0.05,\n",
    "                               trials=200, use_exact_f=True, verbose=False):\n",
    "    \"\"\"Run monte_carlo_polar_matrix for multiple N values, build a DataFrame and plot BER.\n",
    "       - N_list: iterable of powers-of-two (e.g., [8,16,32,64,128])\n",
    "       - K_ratio: fraction of N to use as K (e.g., 0.5)\n",
    "    \"\"\"\n",
    "    rows = []\n",
    "    for N in N_list:\n",
    "        K = int(N * K_ratio)\n",
    "        if verbose:\n",
    "            print(f\"Running N={N}, K={K}, p_ch={p_channel}\")\n",
    "        ber, bler = monte_carlo_polar_matrix(N=N, K=K, p_design=p_design, p_channel=p_channel,\n",
    "                                             trials=trials, use_exact_f=use_exact_f, verbose=verbose)\n",
    "        rows.append({\"N\": N, \"K\": K, \"p\": p_channel, \"BER\": ber, \"BLER\": bler})\n",
    "    df = pd.DataFrame(rows).set_index(\"N\")\n",
    "    # Plot BER\n",
    "    fig, ax = plt.subplots(figsize=(7,4))\n",
    "    ax.plot(df.index, df[\"BER\"], marker=\"o\", linestyle=\"-\")\n",
    "    ax.set_xscale(\"log\", basex=2)\n",
    "    ax.set_xticks(df.index)\n",
    "    ax.set_xticklabels(df.index)\n",
    "    ax.set_xlabel(\"N (block length)\")\n",
    "    ax.set_ylabel(\"BER\")\n",
    "    ax.set_title(f\"Polar BER (p_channel={p_channel}, p_design={p_design})\")\n",
    "    ax.grid(True, which=\"both\", ls=\"--\", alpha=0.4)\n",
    "    plt.show()\n",
    "    return df\n",
    "\n",
    "# ----------------------------\n",
    "# Quick convenience test runner\n",
    "# ----------------------------\n",
    "def quick_sanity_and_plot():\n",
    "    print(\"Run deterministic checks for a few N\")\n",
    "    for N in (4, 8, 16, 32):\n",
    "        ok = deterministic_debug_once(N=N, K=N//2, p_design=0.01, use_exact_f=True, verbose=True)\n",
    "        print(\"deterministic ok:\", ok, \"\\n\" + \"-\"*40)\n",
    "    print(\"Now run a small sweep and plot (this may take some time)...\")\n",
    "    df = monte_carlo_sweep_and_plot([8,16,32,64], K_ratio=0.5, p_design=0.05, p_channel=0.05,\n",
    "                                    trials=200, use_exact_f=True, verbose=False)\n",
    "    print(\"\\nResults DataFrame:\")\n",
    "    display(df)\n",
    "    return df\n",
    "\n",
    "# === End of patch ===\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fe24e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 1, 1, 0]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 1, 1, 0]\n",
      "x: [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "llr (sample 16): [20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [0, 0, 1, 1, 1, 1, 0, 0]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 1, 1, 0]\n",
      "expected info (natural): [0, 1, 1, 0]\n",
      "decoded info (natural): [0, 1, 1, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 1, 0, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 1, 0, 1]\n",
      "x: [1, 0, 0, 1, 1, 0, 0, 1]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 0, 1, 1, 0, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 1, 0, 1]\n",
      "expected info (natural): [1, 1, 0, 1]\n",
      "decoded info (natural): [1, 1, 0, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 0, 0]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "x: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "llr (sample 16): [20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "expected info (natural): [0, 0, 0, 0]\n",
      "decoded info (natural): [0, 0, 0, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "x: [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "expected info (natural): [1, 0, 1, 1]\n",
      "decoded info (natural): [1, 0, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 1, 0]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "x: [1, 1, 1, 1, 0, 0, 0, 0]\n",
      "llr (sample 16): [-20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [1, 1, 1, 1, 0, 0, 0, 0]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 1, 0]\n",
      "expected info (natural): [0, 0, 1, 0]\n",
      "decoded info (natural): [0, 0, 1, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 0, 0]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "x: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "expected info (natural): [1, 0, 0, 0]\n",
      "decoded info (natural): [1, 0, 0, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 1, 0, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 1, 0, 1]\n",
      "x: [1, 0, 0, 1, 1, 0, 0, 1]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 0, 1, 1, 0, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 1, 0, 1]\n",
      "expected info (natural): [1, 1, 0, 1]\n",
      "decoded info (natural): [1, 1, 0, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 0, 0]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "x: [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 1, 0, 1, 0, 1, 0]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 0, 0]\n",
      "expected info (natural): [1, 0, 0, 0]\n",
      "decoded info (natural): [1, 0, 0, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "x: [0, 0, 0, 0, 1, 1, 1, 1]\n",
      "llr (sample 16): [20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [0, 0, 0, 0, 1, 1, 1, 1]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "expected info (natural): [0, 0, 1, 1]\n",
      "decoded info (natural): [0, 0, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "x: [0, 0, 0, 0, 1, 1, 1, 1]\n",
      "llr (sample 16): [20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [0, 0, 0, 0, 1, 1, 1, 1]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 1, 1]\n",
      "expected info (natural): [0, 0, 1, 1]\n",
      "decoded info (natural): [0, 0, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 0, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 0, 1]\n",
      "x: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "llr (sample 16): [20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 0, 1]\n",
      "expected info (natural): [1, 0, 0, 1]\n",
      "decoded info (natural): [1, 0, 0, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "x: [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "expected info (natural): [1, 0, 1, 1]\n",
      "decoded info (natural): [1, 0, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "x: [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 1, 0, 0, 1, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 1, 1]\n",
      "expected info (natural): [1, 0, 1, 1]\n",
      "decoded info (natural): [1, 0, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 1, 0, 0]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 1, 0, 0]\n",
      "x: [0, 1, 1, 0, 0, 1, 1, 0]\n",
      "llr (sample 16): [20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [0, 1, 1, 0, 0, 1, 1, 0]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 1, 0, 0]\n",
      "expected info (natural): [1, 1, 0, 0]\n",
      "decoded info (natural): [1, 1, 0, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 1, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 1, 1, 1]\n",
      "x: [1, 1, 0, 0, 0, 0, 1, 1]\n",
      "llr (sample 16): [-20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 1, 0, 0, 0, 0, 1, 1]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 1, 1, 1]\n",
      "expected info (natural): [0, 1, 1, 1]\n",
      "decoded info (natural): [0, 1, 1, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 0, 0]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "x: [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "llr (sample 16): [20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 0, 0]\n",
      "expected info (natural): [0, 0, 0, 0]\n",
      "decoded info (natural): [0, 0, 0, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 0, 0, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 0, 0, 1]\n",
      "x: [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "llr (sample 16): [20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [0, 1, 0, 1, 0, 1, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 0, 0, 1]\n",
      "expected info (natural): [1, 0, 0, 1]\n",
      "decoded info (natural): [1, 0, 0, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [0, 0, 0, 1]\n",
      "u (full, natural): [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "x: [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "llr (sample 16): [-20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [1, 1, 1, 1, 1, 1, 1, 1]\n",
      "u_hat (natural): [0, 0, 0, 0, 0, 0, 0, 1]\n",
      "expected info (natural): [0, 0, 0, 1]\n",
      "decoded info (natural): [0, 0, 0, 1]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 1, 1, 0]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 1, 1, 0]\n",
      "x: [1, 0, 0, 1, 0, 1, 1, 0]\n",
      "llr (sample 16): [-20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641]\n",
      "u_hat (canonical): [1, 0, 0, 1, 0, 1, 1, 0]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 1, 1, 0]\n",
      "expected info (natural): [1, 1, 1, 0]\n",
      "decoded info (natural): [1, 1, 1, 0]\n",
      "match? True\n",
      "=== Deterministic Debug ===\n",
      "N, K: 8 4\n",
      "info_positions (natural): [3 5 6 7]\n",
      "info_positions (canonical): [3 5 6 7]\n",
      "frozen_mask (natural): [1 1 1 0 1 0 0 0]\n",
      "frozen_mask (canonical): [1 1 1 0 1 0 0 0]\n",
      "msg: [1, 1, 1, 1]\n",
      "u (full, natural): [0, 0, 0, 1, 0, 1, 1, 1]\n",
      "x: [0, 1, 1, 0, 1, 0, 0, 1]\n",
      "llr (sample 16): [20.72326583594641, -20.72326583594641, -20.72326583594641, 20.72326583594641, -20.72326583594641, 20.72326583594641, 20.72326583594641, -20.72326583594641]\n",
      "u_hat (canonical): [0, 1, 1, 0, 1, 0, 0, 1]\n",
      "u_hat (natural): [0, 0, 0, 1, 0, 1, 1, 1]\n",
      "expected info (natural): [1, 1, 1, 1]\n",
      "decoded info (natural): [1, 1, 1, 1]\n",
      "match? True\n",
      "ALL GOOD\n"
     ]
    }
   ],
   "source": [
    "for _ in range(20):\n",
    "    ok = deterministic_debug_once()\n",
    "    if not ok:\n",
    "        print(\"FAIL\")\n",
    "        break\n",
    "else:\n",
    "    print(\"ALL GOOD\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0284d822",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 0/200: bit_err=0, block_err=0\n",
      "Trial 20/200: bit_err=78, block_err=4\n",
      "Trial 40/200: bit_err=165, block_err=9\n",
      "Trial 60/200: bit_err=173, block_err=10\n",
      "Trial 80/200: bit_err=193, block_err=12\n",
      "Trial 100/200: bit_err=207, block_err=14\n",
      "Trial 120/200: bit_err=215, block_err=15\n",
      "Trial 140/200: bit_err=239, block_err=19\n",
      "Trial 160/200: bit_err=255, block_err=21\n",
      "Trial 180/200: bit_err=267, block_err=23\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0.021796875, 0.125)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "monte_carlo_polar_matrix()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50954480",
   "metadata": {},
   "source": [
    "Testing different values of N for deterministic tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "18d8ccf3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "16 deterministic: True\n",
      "32 deterministic: True\n",
      "64 deterministic: True\n",
      "128 deterministic: True\n"
     ]
    }
   ],
   "source": [
    "for N in (16, 32, 64, 128):\n",
    "    ok = True\n",
    "    for _ in range(50):\n",
    "        if not deterministic_debug_once(N=N, K=N//2, p_design=0.01, verbose=False):\n",
    "            ok = False\n",
    "            break\n",
    "    print(N, \"deterministic:\", ok)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c9f7f8",
   "metadata": {},
   "source": [
    "Testing N = 128 and K = 64 with different noise values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "40d6ef2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p=0.010  BER=0.0001  BLER=0.0005\n",
      "p=0.020  BER=0.0010  BLER=0.0050\n",
      "p=0.050  BER=0.0168  BLER=0.0860\n",
      "p=0.100  BER=0.1720  BLER=0.6200\n",
      "p=0.150  BER=0.3634  BLER=0.9555\n",
      "p=0.200  BER=0.4457  BLER=0.9985\n"
     ]
    }
   ],
   "source": [
    "ps = [0.01, 0.02, 0.05, 0.1, 0.15, 0.2]\n",
    "for p in ps:\n",
    "    ber, bler = monte_carlo_polar_matrix(\n",
    "        N=128,\n",
    "        K=64,\n",
    "        p_channel=p,\n",
    "        trials=2000,\n",
    "        use_exact_f=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(f\"p={p:0.3f}  BER={ber:0.4f}  BLER={bler:0.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b73607a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64 0.018109375 0.069\n",
      "128 0.01721875 0.085\n",
      "256 0.0106953125 0.0835\n"
     ]
    }
   ],
   "source": [
    "for N in (64, 128, 256):\n",
    "    ber, bler = monte_carlo_polar_matrix(\n",
    "        N=N, K=N//2, p_channel=0.05,\n",
    "        trials=2000, use_exact_f=True,\n",
    "        verbose=False\n",
    "    )\n",
    "    print(N, ber, bler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a1ca4544",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25 0.0 0.0\n",
      "0.5 0.014625 0.0795\n",
      "0.75 0.24194791666666668 0.8055\n"
     ]
    }
   ],
   "source": [
    "for K_ratio in (0.25, 0.5, 0.75):\n",
    "    ber, bler = monte_carlo_polar_matrix(\n",
    "        N=128, K=int(128*K_ratio), p_channel=0.05,\n",
    "        trials=2000, use_exact_f=True, verbose=False\n",
    "    )\n",
    "    print(K_ratio, ber, bler)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee3e300a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running N=64, K=32, p_ch=0.05\n",
      "Trial 0/2000: bit_err=0, block_err=0\n",
      "Trial 200/2000: bit_err=107, block_err=14\n",
      "Trial 400/2000: bit_err=232, block_err=29\n",
      "Trial 600/2000: bit_err=377, block_err=48\n",
      "Trial 800/2000: bit_err=557, block_err=66\n",
      "Trial 1000/2000: bit_err=646, block_err=81\n",
      "Trial 1200/2000: bit_err=786, block_err=98\n",
      "Trial 1400/2000: bit_err=941, block_err=114\n",
      "Trial 1600/2000: bit_err=1012, block_err=123\n",
      "Trial 1800/2000: bit_err=1165, block_err=139\n",
      "Running N=128, K=64, p_ch=0.05\n",
      "Trial 0/2000: bit_err=0, block_err=0\n",
      "Trial 200/2000: bit_err=219, block_err=19\n",
      "Trial 400/2000: bit_err=498, block_err=41\n",
      "Trial 600/2000: bit_err=841, block_err=68\n",
      "Trial 800/2000: bit_err=1100, block_err=91\n",
      "Trial 1000/2000: bit_err=1364, block_err=109\n",
      "Trial 1200/2000: bit_err=1521, block_err=122\n",
      "Trial 1400/2000: bit_err=1701, block_err=137\n",
      "Trial 1600/2000: bit_err=1952, block_err=157\n",
      "Trial 1800/2000: bit_err=2146, block_err=175\n",
      "Running N=256, K=128, p_ch=0.05\n",
      "Trial 0/2000: bit_err=0, block_err=0\n",
      "Trial 200/2000: bit_err=206, block_err=14\n",
      "Trial 400/2000: bit_err=458, block_err=25\n",
      "Trial 600/2000: bit_err=900, block_err=45\n",
      "Trial 800/2000: bit_err=1072, block_err=58\n",
      "Trial 1000/2000: bit_err=1338, block_err=72\n",
      "Trial 1200/2000: bit_err=1528, block_err=84\n",
      "Trial 1400/2000: bit_err=1768, block_err=102\n",
      "Trial 1600/2000: bit_err=2066, block_err=121\n",
      "Trial 1800/2000: bit_err=2432, block_err=139\n",
      "Running N=512, K=256, p_ch=0.05\n",
      "Trial 0/2000: bit_err=0, block_err=0\n",
      "Trial 200/2000: bit_err=144, block_err=9\n",
      "Trial 400/2000: bit_err=562, block_err=23\n",
      "Trial 600/2000: bit_err=708, block_err=29\n",
      "Trial 800/2000: bit_err=1100, block_err=43\n",
      "Trial 1000/2000: bit_err=1246, block_err=48\n",
      "Trial 1200/2000: bit_err=1592, block_err=62\n",
      "Trial 1400/2000: bit_err=2075, block_err=79\n",
      "Trial 1600/2000: bit_err=2495, block_err=91\n",
      "Trial 1800/2000: bit_err=2816, block_err=103\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "LogScale.__init__() got an unexpected keyword argument 'basex'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m N_list = [\u001b[32m64\u001b[39m, \u001b[32m128\u001b[39m, \u001b[32m256\u001b[39m, \u001b[32m512\u001b[39m]\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m \u001b[43mmonte_carlo_sweep_and_plot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mN_list\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK_ratio\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_design\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp_channel\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m0.05\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m      3\u001b[39m \u001b[43m                           \u001b[49m\u001b[43mtrials\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2000\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muse_exact_f\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 318\u001b[39m, in \u001b[36mmonte_carlo_sweep_and_plot\u001b[39m\u001b[34m(N_list, K_ratio, p_design, p_channel, trials, use_exact_f, verbose)\u001b[39m\n\u001b[32m    316\u001b[39m fig, ax = plt.subplots(figsize=(\u001b[32m7\u001b[39m,\u001b[32m4\u001b[39m))\n\u001b[32m    317\u001b[39m ax.plot(df.index, df[\u001b[33m\"\u001b[39m\u001b[33mBER\u001b[39m\u001b[33m\"\u001b[39m], marker=\u001b[33m\"\u001b[39m\u001b[33mo\u001b[39m\u001b[33m\"\u001b[39m, linestyle=\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m318\u001b[39m \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_xscale\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mlog\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbasex\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    319\u001b[39m ax.set_xticks(df.index)\n\u001b[32m    320\u001b[39m ax.set_xticklabels(df.index)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\axes\\_base.py:74\u001b[39m, in \u001b[36m_axis_method_wrapper.__set_name__.<locals>.wrapper\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m     73\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper\u001b[39m(\u001b[38;5;28mself\u001b[39m, *args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m74\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mget_method\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\axis.py:805\u001b[39m, in \u001b[36mAxis._set_axes_scale\u001b[39m\u001b[34m(self, value, **kwargs)\u001b[39m\n\u001b[32m    802\u001b[39m old_default_lims = (\u001b[38;5;28mself\u001b[39m.get_major_locator()\n\u001b[32m    803\u001b[39m                     .nonsingular(-np.inf, np.inf))\n\u001b[32m    804\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m ax \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._get_shared_axes():\n\u001b[32m--> \u001b[39m\u001b[32m805\u001b[39m     \u001b[43max\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_axis_map\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_set_scale\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    806\u001b[39m     ax._update_transScale()\n\u001b[32m    807\u001b[39m     ax.stale = \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\axis.py:763\u001b[39m, in \u001b[36mAxis._set_scale\u001b[39m\u001b[34m(self, value, **kwargs)\u001b[39m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_set_scale\u001b[39m(\u001b[38;5;28mself\u001b[39m, value, **kwargs):\n\u001b[32m    762\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(value, mscale.ScaleBase):\n\u001b[32m--> \u001b[39m\u001b[32m763\u001b[39m         \u001b[38;5;28mself\u001b[39m._scale = \u001b[43mmscale\u001b[49m\u001b[43m.\u001b[49m\u001b[43mscale_factory\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    764\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    765\u001b[39m         \u001b[38;5;28mself\u001b[39m._scale = value\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\AppData\\Roaming\\Python\\Python312\\site-packages\\matplotlib\\scale.py:709\u001b[39m, in \u001b[36mscale_factory\u001b[39m\u001b[34m(scale, axis, **kwargs)\u001b[39m\n\u001b[32m    700\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    701\u001b[39m \u001b[33;03mReturn a scale class by name.\u001b[39;00m\n\u001b[32m    702\u001b[39m \n\u001b[32m   (...)\u001b[39m\u001b[32m    706\u001b[39m \u001b[33;03maxis : `~matplotlib.axis.Axis`\u001b[39;00m\n\u001b[32m    707\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m    708\u001b[39m scale_cls = _api.check_getitem(_scale_mapping, scale=scale)\n\u001b[32m--> \u001b[39m\u001b[32m709\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mscale_cls\u001b[49m\u001b[43m(\u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mTypeError\u001b[39m: LogScale.__init__() got an unexpected keyword argument 'basex'"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x400 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "N_list = [64, 128, 256, 512]\n",
    "monte_carlo_sweep_and_plot(N_list, K_ratio=0.5, p_design=0.05, p_channel=0.05,\n",
    "                           trials=2000, use_exact_f=True, verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
